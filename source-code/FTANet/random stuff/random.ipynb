{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mean std for spec extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pyprind\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n"
     ]
    }
   ],
   "source": [
    "spec_list = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\spec_feature\\year2007*.npy\"):\n",
    "    spec_list.append(f)\n",
    "\n",
    "print(len(spec_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 32, 513)\n",
      "(26, 32, 513)\n"
     ]
    }
   ],
   "source": [
    "feature1 = np.load(spec_list[0])\n",
    "feature2 = np.load(spec_list[1])\n",
    "fused = np.concatenate((feature1, feature2), axis=0)\n",
    "print(fused.shape)\n",
    "print(feature1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(1//4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32,) (32,)\n"
     ]
    }
   ],
   "source": [
    "arrays = [np.array(x) for x in fused]\n",
    "mean_2007 = np.asarray([np.mean(k) for k in zip(*arrays)])\n",
    "std_2007 = np.asarray([np.std(k) for k in zip(*arrays)])\n",
    "print(mean_2007.shape, std_2007.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(np.nanmean(arrays, axis=0), np.mean(arrays, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filter List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyprind\n",
    "import numpy as np\n",
    "\n",
    "with open(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\MIR-QBSH\\querywav_list.txt\",'r') as f:\n",
    "    querylist = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454\n"
     ]
    }
   ],
   "source": [
    "list_2007 = list(filter(lambda k: 'year2007' in k, querylist))\n",
    "print(len(list_2007))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. test data train shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "train_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\pl_train_file_2007.pkl'\n",
    "valid_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\pl_valid_file_2007.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    xlist, ylist = pickle.load(f)\n",
    "    \n",
    "xlist = np.asarray(xlist)\n",
    "ylist = np.asarray(ylist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2541, 128, 320, 3) (2541, 128, 321)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(xlist),np.shape(ylist))\n",
    "print(type(xlist), type(ylist))\n",
    "# spec : (11804, 32, 513)\n",
    "# cfp : (2541, 320, 128, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "for train, test in kfold.split(xlist, ylist):\n",
    "    x, y = xlist[test], ylist[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "spec_feature = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\spec_feature\\year2007-person00001-00011.npy'\n",
    "\n",
    "feature = np.load(spec_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 32, 513)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "train_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_spec\\pd2_train_file_norm.pkl'\n",
    "valid_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_spec\\pd2_valid_file_norm.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    xlist, ylist = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14742, 32, 513, 1) (14742, 32, 722)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(xlist),np.shape(ylist))\n",
    "print(type(xlist), type(ylist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2366, 32, 513, 1) (2366, 32, 722)\n"
     ]
    }
   ],
   "source": [
    "with open(valid_path, 'rb') as f:\n",
    "    xlist, ylist = pickle.load(f)\n",
    "    \n",
    "print(np.shape(xlist),np.shape(ylist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 513, 1) (32, 513, 1)\n",
      "(32, 513) (32, 513)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis')\n",
    "\n",
    "x_train_mean = np.load('E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\FTANet\\\\utils_s\\\\x_data_mean.npy')   \n",
    "x_train_std = np.load('E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\FTANet\\\\utils_s\\\\x_data_std.npy')\n",
    "x_train_mean_2007 = np.load('E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\FTANet\\\\utils_s\\\\x_data_mean_2007.npy')   \n",
    "x_train_std_2007 = np.load('E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\FTANet\\\\utils_s\\\\x_data_std_2007.npy')\n",
    "\n",
    "print(x_train_mean.shape, x_train_std.shape)\n",
    "print(x_train_mean_2007.shape, x_train_std_2007.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 513)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load('E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\JDC\\\\melodyExtraction_JDC\\\\x_data_mean_total_31.npy').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 513)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean = x_train_mean[:, :, 0]\n",
    "x_mean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. check if label is more than 83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aman ngab\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "\n",
    "list_file = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_praat\\\\mir-qbsh\\year2007*.csv\"):\n",
    "    list_file.append(f)\n",
    "\n",
    "lebih = False\n",
    "\n",
    "for file in list_file:\n",
    "    pitch = genfromtxt(file, delimiter=',')\n",
    "    pitch = pitch[1:, 1]\n",
    "\n",
    "    # menyamakan timeframe\n",
    "    pitch = np.insert(pitch, 0, 0)\n",
    "    pitch = np.insert(pitch, 0, 0)\n",
    "    pitch = np.insert(pitch, -1, pitch[-1])\n",
    "    pitch = np.insert(pitch, -1, pitch[-1])\n",
    "    \n",
    "    for j in range(len(pitch)):\n",
    "        if pitch[j] > 0.0 :\n",
    "            if np.round(16*(69.0 + 12.0*np.log2(pitch[j]/440.0)))/float(16) > 83:\n",
    "                lebih = True\n",
    "    \n",
    "if lebih:\n",
    "    print(\"ada yg lebih anyink\")\n",
    "else:\n",
    "    print(\"aman ngab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. check cfp dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please specify the \"origin\" argument (URL of the file to download).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-074a110cb921>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mvalid_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\pl_valid_file_2007.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    208\u001b[0m   \"\"\"\n\u001b[0;32m    209\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0morigin\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     raise ValueError('Please specify the \"origin\" argument (URL of the file '\n\u001b[0m\u001b[0;32m    211\u001b[0m                      'to download).')\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please specify the \"origin\" argument (URL of the file to download)."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# cfp\n",
    "train_file = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\pl_train_file_2007.pkl'\n",
    "valid_file = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\pl_valid_file_2007.pkl'\n",
    "\n",
    "with open(tf.keras.utils.get_file(train_file), 'rb') as f:\n",
    "    x_train, y_train = pickle.load(f)\n",
    "\n",
    "with open(tf.keras.utils.get_file(valid_file), 'rb') as f:\n",
    "    x_valid, y_valid = pickle.load(f)\n",
    "    \n",
    "\n",
    "print(np.shape(x_train), np.shape(y_train))\n",
    "print(np.shape(x_valid), np.shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(726, 128, 320, 3) (726, 128, 321)\n",
      "(91, 2, 128, 320, 3) (91, 249, 2)\n"
     ]
    }
   ],
   "source": [
    "train_file = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\s2007_train_file_s.pkl'\n",
    "valid_file = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_r\\s2007_valid_file_s.pkl'\n",
    "\n",
    "with open(train_file, 'rb') as f:\n",
    "    x_train, y_train = pickle.load(f)\n",
    "\n",
    "with open(valid_file, 'rb') as f:\n",
    "    x_valid, y_valid = pickle.load(f)\n",
    "    \n",
    "\n",
    "print(np.shape(x_train), np.shape(y_train))\n",
    "print(np.shape(x_valid), np.shape(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 320, 799) (799,)\n",
      "(799,)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "sys.path.insert(0, 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis')\n",
    "\n",
    "from FTANet_melodic.cfp import cfp_process\n",
    "file = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\MIR-QBSH\\waveFile\\year2007\\person00006\\\\00012.wav'\n",
    "file_label = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_praat\\mir-qbsh\\year2007-person00006-00012.csv'\n",
    "data, CenFreq, time_arr = cfp_process(file, model_type='vocal', sr=8000, hop=80, window=768)\n",
    "print(np.shape(data), np.shape(time_arr))\n",
    "pitch = genfromtxt(file_label, delimiter=',') \n",
    "pitch = pitch[1:, 1]\n",
    "# menyamakan timeframe\n",
    "pitch = np.insert(pitch, 0, 0)\n",
    "pitch = np.insert(pitch, -1, pitch[-1])\n",
    "print(np.shape(pitch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = np.arange(0.01, 8, 0.01)\n",
    "ref_arr = np.concatenate((time_arr[:, None], pitch[:, None]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CenFreq(StartFreq=80, StopFreq=1000, NumPerOct=48):\n",
    "    Nest = int(np.ceil(np.log2(StopFreq/StartFreq))*NumPerOct)\n",
    "    central_freq = []\n",
    "    for i in range(0, Nest):\n",
    "        CenFreq = StartFreq*pow(2, float(i)/NumPerOct)\n",
    "        if CenFreq < StopFreq:\n",
    "            if i == 0 :\n",
    "                central_freq.append(0)\n",
    "            else:\n",
    "                central_freq.append(round(CenFreq, 3))\n",
    "        else:\n",
    "            break\n",
    "    return central_freq\n",
    "\n",
    "def seq2map(seq, CenFreq):\n",
    "    CenFreq[0] = 0\n",
    "    gtmap = np.zeros((len(seq), len(CenFreq)))\n",
    "    for i in range(len(seq)):\n",
    "        v = np.where(CenFreq == seq[i])\n",
    "        gtmap[i, v[0][0]] = 1\n",
    "    return gtmap \n",
    "\n",
    "def batchize(data, gt, xlist, ylist, size=128):\n",
    "    # menghilangkan error perbedaan shape\n",
    "    if data.shape[-1] != gt.shape[0]:\n",
    "        new_length = min(data.shape[-1], gt.shape[0])\n",
    "\n",
    "        data = data[:, :, :new_length]\n",
    "        gt = gt[:new_length, :]\n",
    "        \n",
    "    num = int(gt.shape[0] / size)\n",
    "    if gt.shape[0] % size != 0:\n",
    "        num += 1\n",
    "    for i in range(num):\n",
    "        if (i + 1) * size > gt.shape[0]:\n",
    "            batch_x = np.zeros((data.shape[0], data.shape[1], size))\n",
    "            batch_y = np.zeros((size, gt.shape[-1]))\n",
    "            \n",
    "            tmp_x = data[:, :, i * size:]\n",
    "            tmp_y = gt[i * size:, :]            \n",
    "            \n",
    "            batch_x[:, :, :tmp_x.shape[-1]] += tmp_x \n",
    "            batch_y[:tmp_y.shape[0], :] += tmp_y\n",
    "            xlist.append(batch_x.transpose(2, 1, 0))\n",
    "            ylist.append(batch_y)\n",
    "            break\n",
    "        else:\n",
    "            batch_x = data[:, :, i * size:(i + 1) * size]\n",
    "            batch_y = gt[i * size:(i + 1) * size, :]        \n",
    "            xlist.append(batch_x.transpose(2, 1, 0))\n",
    "            ylist.append(batch_y)\n",
    "\n",
    "    return xlist, ylist, num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799, 321)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CenFreq = get_CenFreq(StartFreq=31, StopFreq=1250, NumPerOct=60) # (321) #参数是特征提取时就固定的\n",
    "\n",
    "for index in range(len(pitch)):\n",
    "    if pitch[index] != 0:\n",
    "        pos = (np.abs(CenFreq-pitch[index])).argmin()        \n",
    "        pitch[index] = CenFreq[pos]\n",
    "\n",
    "mapping = seq2map(pitch, CenFreq)\n",
    "mapping.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 128, 320, 3) (7, 128, 321)\n"
     ]
    }
   ],
   "source": [
    "xlist = []\n",
    "ylist = []\n",
    "xlist, ylist, num = batchize(data, mapping, xlist, ylist, 128)\n",
    "print(np.shape(xlist), np.shape(ylist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896, 321)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_train (2541, 321, 128)\n",
    "np.concatenate(ylist, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(mapping, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(896, 321)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(896, 321)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.concatenate(ylist, axis=0).shape)\n",
    "preds = iseg(np.asarray(ylist)) #iseg kontol\n",
    "np.shape(preds)\n",
    "# SAMA AJA ANJINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(896,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(np.concatenate(ylist, axis=0), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est(output, CenFreq, time_arr):\n",
    "    CenFreq[0] = 0\n",
    "    est_time = time_arr\n",
    "    est_freq = np.argmax(output, axis=1).astype(float)\n",
    "\n",
    "    for j in range(len(est_freq)):\n",
    "        est_freq[j] = CenFreq[int(est_freq[j])]\n",
    "        \n",
    "    if len(est_freq) != len(est_time):\n",
    "        new_length = min(len(est_freq), len(est_time))\n",
    "        est_freq = est_freq[:new_length]\n",
    "        est_time = est_time[:new_length]\n",
    "\n",
    "    est_arr = np.concatenate((est_time[:, None], est_freq[:, None]), axis=1)\n",
    "    return est_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7, 128, 321)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "y.append(ylist)\n",
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = np.arange(0.01, 8, 0.01)\n",
    "est_arr = est(np.concatenate(np.concatenate(y, axis=0), axis=0), CenFreq, time_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799, 2) (799, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(ref_arr), np.shape(est_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100.,   0., 100., 100., 100.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis')\n",
    "\n",
    "from FTANet.evaluator import melody_eval\n",
    "\n",
    "eval_arr = melody_eval(ref_arr, est_arr)\n",
    "eval_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. generate short feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining\\\\train_file_fix.txt'\n",
    "valid_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining\\\\valid_file_fix.txt'\n",
    "\n",
    "path = ['E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\database\\\\cfp_feature_github\\\\year2009-person00014-00029.npy', 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis\\\\database\\\\MIR-QBSH\\\\f0File\\\\year2009-person00014-00029.csv']\n",
    "\n",
    "feature = np.load(path[0])\n",
    "label = pd.read_csv(path[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 320, 799)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_label =  np.asarray(label['f0'])\n",
    "time_label =  np.asarray(label['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_index = np.arange(0.01, 8, 0.01)\n",
    "time_index = list(np.around(time_index ,2))\n",
    "# time_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_lbl = []\n",
    "time_index = list(time_index)\n",
    "for i in range(len(time_label)):\n",
    "    index_lbl.append(time_index.index(time_label[i]))\n",
    "\n",
    "len(index_lbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 320, 249)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_short = np.zeros((feature.shape[0], feature.shape[1], len(index_lbl)))\n",
    "for i in range(len(index_lbl)):\n",
    "    feature_short[:,:,i] = feature[:,:,index_lbl[i]]\n",
    "\n",
    "feature_short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. check midi in each year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "midis = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\MIR-QBSH\\midiFile\\*.mid\"):\n",
    "    midis.append(f[-9:-4])\n",
    "\n",
    "x_list_file = []\n",
    "y_list_file = []\n",
    "for midi in midis:\n",
    "    count = 1\n",
    "    list_file = glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\cfp_feature_github\\*{}.npy\".format(midi))\n",
    "    random.shuffle(list_file)\n",
    "    for f in list_file:\n",
    "        if count <= 20 :\n",
    "            x_list_file.append(f)\n",
    "            y_list_file.append(f.replace('npy', 'csv').replace('E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\cfp_feature_github\\\\', 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\MIR-QBSH\\\\f0File\\\\'))\n",
    "            count +=1\n",
    "\n",
    "print(len(y_list_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "values, counts = np.unique(np.array(x_list_file), return_counts=True)\n",
    "for i in range(len(values)):\n",
    "    print(values[i], ' : ', counts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, counts = np.unique(np.array(x_list_full), return_counts=True)\n",
    "for i in range(len(values)):\n",
    "    print(values[i], ' : ', counts[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. test eavlueate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "valid_path = 'E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\retraining_spec\\pd2_valid_file_norm.pkl'\n",
    "\n",
    "with open(valid_path, 'rb') as f:\n",
    "    xlist, ylist = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3692, 32, 722)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ylist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_total = ylist.shape[0] * ylist.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118144"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def est(y_predict, resolution = 16):\n",
    "    pitch_range = np.arange(38, 83 + 1.0/resolution, 1.0/resolution)\n",
    "    pitch_range = np.concatenate([np.zeros(1), pitch_range])\n",
    "    \n",
    "    num_total = y_predict[0].shape[0] * y_predict[0].shape[1]\n",
    "    est_pitch = np.zeros(num_total)\n",
    "    y_predict = np.reshape(y_predict[0], (num_total, y_predict[0].shape[2]))  # origin\n",
    "    \n",
    "    for i in range(y_predict.shape[0]):\n",
    "        index_predict = np.argmax(y_predict[i, :])\n",
    "        pitch_MIDI = pitch_range[np.int32(index_predict)]\n",
    "        if pitch_MIDI >= 38 and pitch_MIDI <= 83:\n",
    "            est_pitch[i] = 2 ** ((pitch_MIDI - 69) / 12.) * 440\n",
    "        \n",
    "    est_time = np.arange(0, num_total, 0.01)\n",
    "    est_arr = np.concatenate((est_time[:, None], est_pitch[:, None]), axis=1)\n",
    "    return est_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. get time_arr for midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "sys.path.insert(0, 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis')\n",
    "\n",
    "from FTANet.cfp import getTimeArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\MIR-QBSH\\querywav_list.txt\",'r') as f:\n",
    "    querylist = f.readlines()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "row = querylist[0].replace(\"\\n\",\"\")\n",
    "time_arr1 = getTimeArr(row, model_type='vocal', sr=8000, hop=256, window=768)\n",
    "time_arr2 = getTimeArr(row, model_type='vocal', sr=8000, hop=256, window=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(time_arr1 == time_arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. get pitch range extracted melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "query_praat = []\n",
    "query_fta = []\n",
    "query_fta_rds = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_praat\\*\\*.csv\"):\n",
    "    query_praat.append(f)\n",
    "    \n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_ftanet\\\\rc\\*\\*.csv\"):\n",
    "    query_fta.append(f)\n",
    "    \n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_ftanet\\\\rds\\*\\*.csv\"):\n",
    "    query_fta_rds.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_midi_mirqbh = []\n",
    "query_midi_ioacas = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\MIR-QBSH\\\\midi_note\\*.csv\"):\n",
    "    query_midi_mirqbh.append(f)\n",
    "    \n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\IOACAS_QBH\\\\midi_note\\*.csv\"):\n",
    "    query_midi_ioacas.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f0_to_semitone(f0):\n",
    "    import math\n",
    "    semitone = []\n",
    "    for f in f0:\n",
    "        if f != 0:\n",
    "            semitone.append(round(12*math.log((f/440),2)+69))\n",
    "        else:\n",
    "            semitone.append(f)\n",
    "    return semitone\n",
    "\n",
    "def get_pitch(list, v = 'normal'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    all_f0 = []\n",
    "    for query_file in list:\n",
    "        if v == 'normal':\n",
    "            pitch = pd.read_csv(query_file)\n",
    "            try:\n",
    "                f0 = pitch['f0'].to_numpy()\n",
    "                f0 = f0_to_semitone(f0)\n",
    "            except:\n",
    "                f0 = pitch['semitone'].to_numpy()\n",
    "            all_f0.append(f0)\n",
    "        else:\n",
    "            original_query = np.loadtxt(query_file, delimiter = \" \", dtype = 'str')\n",
    "            f0 = []\n",
    "            for note in original_query:\n",
    "                f0.append(float(note[1]))\n",
    "            f0 = f0_to_semitone(f0)\n",
    "            all_f0.append(f0)\n",
    "    # print(np.shape(all_f0))\n",
    "    all_f0 = np.concatenate(all_f0, axis=0)    \n",
    "    all_f0 = np.delete(all_f0, np.where(all_f0 == 0))\n",
    "    return all_f0.tolist()\n",
    "\n",
    "def get_range(f0):\n",
    "    import math\n",
    "    last_pitch = None\n",
    "    range_pitch = []\n",
    "    for pitch in f0:\n",
    "        if last_pitch is None:\n",
    "            last_pitch = pitch\n",
    "        else:\n",
    "            range_pitch.append(round(abs(pitch-last_pitch), 2))\n",
    "            last_pitch = pitch\n",
    "    return range_pitch\n",
    "\n",
    "def count_range(semitone):\n",
    "    from collections import Counter\n",
    "    x = Counter(semitone)\n",
    "    x_srted = sorted(x.items(), key=lambda i: i[0], reverse=True)\n",
    "    return x_srted\n",
    "\n",
    "def get_stat(list):\n",
    "    import numpy as np\n",
    "    print(np.mean(list))\n",
    "    print(np.median(list))\n",
    "    print(np.min(list))\n",
    "    print(np.max(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044813218941455374\n",
      "0.0\n",
      "0\n",
      "21\n",
      "[(21, 1), (17, 1), (16, 1), (15, 4), (12, 25), (11, 1), (10, 14), (9, 42), (8, 24), (7, 103), (5, 177), (4, 159), (3, 500), (2, 1485), (1, 338), (0, 179772)]\n"
     ]
    }
   ],
   "source": [
    "query_midi_mirqbh = get_pitch(query_midi_mirqbh)\n",
    "range_midi_mirqbh = get_range(query_midi_mirqbh)\n",
    "sorted_range_midi_mirqbh = count_range(range_midi_mirqbh)\n",
    "get_stat(range_midi_mirqbh)\n",
    "print(sorted_range_midi_mirqbh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050546182422507455\n",
      "0.0\n",
      "0\n",
      "36\n",
      "[(36, 2), (31, 1), (27, 2), (26, 5), (24, 8), (23, 5), (22, 2), (21, 4), (20, 2), (19, 5), (18, 6), (17, 28), (16, 20), (15, 47), (14, 65), (13, 14), (12, 821), (11, 52), (10, 464), (9, 1081), (8, 744), (7, 3325), (6, 71), (5, 5835), (4, 3089), (3, 12511), (2, 31553), (1, 6464), (0, 4021877)]\n"
     ]
    }
   ],
   "source": [
    "query_midi_ioacas = get_pitch(query_midi_ioacas)\n",
    "range_midi_ioacas = get_range(query_midi_ioacas)\n",
    "sorted_range_midi_ioacas = count_range(range_midi_ioacas)\n",
    "get_stat(range_midi_ioacas)\n",
    "print(sorted_range_midi_ioacas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3714930089283859\n",
      "0.0\n",
      "0.0\n",
      "64.0\n",
      "[(64.0, 416), (63.0, 300), (62.0, 357), (61.0, 466), (60.0, 648), (59.0, 626), (58.0, 550), (57.0, 548), (56.0, 590), (55.0, 674), (54.0, 658), (53.0, 762), (52.0, 909), (51.0, 983), (50.0, 920), (49.0, 941), (48.0, 1087), (47.0, 868), (46.0, 799), (45.0, 743), (44.0, 873), (43.0, 1315), (42.0, 1151), (41.0, 1272), (40.0, 2130), (39.0, 2152), (38.0, 2122), (37.0, 2631), (36.0, 3462), (35.0, 2928), (34.0, 3149), (33.0, 3245), (32.0, 3863), (31.0, 4327), (30.0, 3077), (29.0, 3344), (28.0, 4963), (27.0, 3282), (26.0, 2566), (25.0, 3748), (24.0, 6609), (23.0, 3249), (22.0, 2035), (21.0, 2208), (20.0, 4732), (19.0, 9970), (18.0, 3808), (17.0, 1739), (16.0, 1732), (15.0, 1771), (14.0, 2324), (13.0, 9188), (12.0, 30802), (11.0, 8200), (10.0, 2734), (9.0, 2331), (8.0, 2768), (7.0, 3736), (6.0, 3060), (5.0, 4757), (4.0, 6521), (3.0, 13136), (2.0, 24847), (1.0, 310449), (0.0, 2741453)]\n"
     ]
    }
   ],
   "source": [
    "semitone_fta_rds = get_pitch(query_fta_rds)\n",
    "range_fta_rds = get_range(semitone_fta_rds)\n",
    "sorted_range_fta_rds = count_range(range_fta_rds)\n",
    "get_stat(range_fta_rds)\n",
    "print(sorted_range_fta_rds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3350196301357873\n",
      "0.0\n",
      "0.0\n",
      "64.0\n",
      "[(64.0, 1931), (63.0, 444), (62.0, 136), (61.0, 126), (60.0, 152), (59.0, 38), (58.0, 81), (57.0, 121), (56.0, 413), (55.0, 652), (54.0, 487), (53.0, 461), (52.0, 400), (51.0, 419), (50.0, 307), (49.0, 474), (48.0, 479), (47.0, 655), (46.0, 649), (45.0, 889), (44.0, 1519), (43.0, 1695), (42.0, 2462), (41.0, 2718), (40.0, 3776), (39.0, 4607), (38.0, 4689), (37.0, 5467), (36.0, 5754), (35.0, 6359), (34.0, 7242), (33.0, 6375), (32.0, 7770), (31.0, 9479), (30.0, 7466), (29.0, 8301), (28.0, 9808), (27.0, 7670), (26.0, 6516), (25.0, 6917), (24.0, 12600), (23.0, 5645), (22.0, 4264), (21.0, 3299), (20.0, 4708), (19.0, 18788), (18.0, 4271), (17.0, 2325), (16.0, 2126), (15.0, 2051), (14.0, 1797), (13.0, 5410), (12.0, 27863), (11.0, 4278), (10.0, 1518), (9.0, 1690), (8.0, 1624), (7.0, 3043), (6.0, 3018), (5.0, 5019), (4.0, 8234), (3.0, 14986), (2.0, 26472), (1.0, 342082), (0.0, 4290792)]\n"
     ]
    }
   ],
   "source": [
    "semitone_fta = get_pitch(query_fta)\n",
    "range_fta = get_range(semitone_fta)\n",
    "sorted_range_fta = count_range(range_fta)\n",
    "get_stat(range_fta)\n",
    "print(sorted_range_fta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2635446840942226\n",
      "0.0\n",
      "0.0\n",
      "36.0\n",
      "[(36.0, 4), (35.0, 17), (34.0, 38), (33.0, 44), (32.0, 62), (31.0, 72), (30.0, 91), (29.0, 143), (28.0, 215), (27.0, 278), (26.0, 395), (25.0, 550), (24.0, 625), (23.0, 677), (22.0, 753), (21.0, 824), (20.0, 892), (19.0, 931), (18.0, 848), (17.0, 836), (16.0, 846), (15.0, 892), (14.0, 950), (13.0, 1203), (12.0, 2680), (11.0, 1206), (10.0, 1036), (9.0, 1155), (8.0, 1283), (7.0, 1764), (6.0, 2539), (5.0, 4080), (4.0, 6413), (3.0, 11491), (2.0, 24473), (1.0, 422958), (0.0, 2898491)]\n"
     ]
    }
   ],
   "source": [
    "semitone_praat = get_pitch(query_praat)\n",
    "range_praat = get_range(semitone_praat)\n",
    "sorted_range_praat = count_range(range_praat)\n",
    "get_stat(range_praat)\n",
    "print(sorted_range_praat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_JDC = []\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_JDC\\*\\*.txt\"):\n",
    "    query_JDC.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11845305253460517\n",
      "0.0\n",
      "0.0\n",
      "26.0\n",
      "[(26.0, 1), (25.0, 2), (24.0, 5), (23.0, 1), (22.0, 2), (21.0, 4), (20.0, 5), (19.0, 24), (18.0, 7), (17.0, 14), (16.0, 16), (15.0, 23), (14.0, 40), (13.0, 131), (12.0, 555), (11.0, 299), (10.0, 349), (9.0, 471), (8.0, 890), (7.0, 1335), (6.0, 2016), (5.0, 3184), (4.0, 5046), (3.0, 8988), (2.0, 15863), (1.0, 200455), (0.0, 2678046)]\n"
     ]
    }
   ],
   "source": [
    "semitone_JDC = get_pitch(query_JDC, v = 'JDC')\n",
    "range_JDC = get_range(semitone_JDC)\n",
    "sorted_range_JDC = count_range(range_JDC)\n",
    "get_stat(range_JDC)\n",
    "print(sorted_range_JDC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. test evaluate with praat and mapping cenfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "sys.path.insert(0, 'E:\\\\Kuliah\\\\S2\\\\Thesis\\\\source code thesis')\n",
    "query_praat = []\n",
    "query_fta = []\n",
    "query_JDC = []\n",
    "\n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_praat\\*\\*.csv\"):\n",
    "    query_praat.append(f)\n",
    "    \n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_ftanet\\\\rc\\*\\*.csv\"):\n",
    "    query_fta.append(f)\n",
    "    \n",
    "for f in glob.glob(\"E:\\Kuliah\\S2\\Thesis\\source code thesis\\database\\\\result_JDC\\*\\*.txt\"):\n",
    "    query_JDC.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CenFreq(StartFreq=80, StopFreq=1000, NumPerOct=48):\n",
    "    Nest = int(np.ceil(np.log2(StopFreq/StartFreq))*NumPerOct)\n",
    "    central_freq = []\n",
    "    for i in range(0, Nest):\n",
    "        CenFreq = StartFreq*pow(2, float(i)/NumPerOct)\n",
    "        if CenFreq < StopFreq:\n",
    "            if i == 0 :\n",
    "                central_freq.append(0)\n",
    "            else:\n",
    "                central_freq.append(round(CenFreq, 3))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return central_freq\n",
    "\n",
    "def load_pitch(querylist, v = 'label'):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from numpy import genfromtxt\n",
    "    labels = []\n",
    "    for query in querylist:\n",
    "        if v != 'JDC':\n",
    "            pitch = genfromtxt(query, delimiter=',')\n",
    "            pitch = pitch[1:,1]              \n",
    "            pitch = np.insert(pitch, 0, 0)\n",
    "            pitch = np.insert(pitch, -1, pitch[-1])\n",
    "            \n",
    "            if v == 'label':\n",
    "                CenFreq = get_CenFreq(StartFreq=31, StopFreq=1250, NumPerOct=60)\n",
    "                for index in range(len(pitch)):\n",
    "                    if pitch[index] != 0:\n",
    "                        pos = (np.abs(CenFreq-pitch[index])).argmin()        \n",
    "                        pitch[index] = CenFreq[pos]\n",
    "            labels.append(pitch)\n",
    "        else:\n",
    "            original_query = np.loadtxt(query, delimiter = \" \", dtype = 'str')\n",
    "            pitch = []\n",
    "            for note in original_query:\n",
    "                pitch.append(float(note[1]))\n",
    "            # del pitch[0]\n",
    "            labels.append(pitch)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def generate_query(pitchs):\n",
    "    import numpy\n",
    "    queries = []\n",
    "    count = 0\n",
    "    for pitch in pitchs:\n",
    "        time_axis = np.arange(0, len(pitch)/100, 0.01)\n",
    "        \n",
    "        if len(time_axis) != len(pitch):\n",
    "            new_length = min(len(time_axis), len(pitch))\n",
    "            time_axis = time_axis[:new_length]\n",
    "            pitch = pitch[:new_length]\n",
    "        \n",
    "        query = np.concatenate((time_axis[:, None], pitch[:, None]), axis=1)\n",
    "        queries.append(query)\n",
    "    return queries\n",
    "    \n",
    "def melody_eval(ref, est):\n",
    "    import mir_eval\n",
    "    \n",
    "    if len(ref) != len(est):\n",
    "        new_length = min(len(ref), len(est))\n",
    "        ref = ref[:new_length]\n",
    "        est = est[:new_length]\n",
    "    \n",
    "    ref_time = ref[:, 0]\n",
    "    ref_freq = ref[:, 1]\n",
    "\n",
    "    est_time = est[:, 0]\n",
    "    est_freq = est[:, 1]\n",
    "    \n",
    "    output_eval = mir_eval.melody.evaluate(ref_time, ref_freq, est_time, est_freq)\n",
    "    VR = output_eval['Voicing Recall'] * 100.0\n",
    "    VFA = output_eval['Voicing False Alarm'] * 100.0\n",
    "    RPA = output_eval['Raw Pitch Accuracy'] * 100.0\n",
    "    RCA = output_eval['Raw Chroma Accuracy'] * 100.0\n",
    "    OA = output_eval['Overall Accuracy'] * 100.0\n",
    "    eval_arr = np.array([VR, VFA, RPA, RCA, OA])\n",
    "    return eval_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitch_labels = load_pitch(query_praat, v = 'label')\n",
    "query_labels = generate_query(pitch_labels)\n",
    "\n",
    "pitch_praats = load_pitch(query_praat, v = 'praat')\n",
    "query_praats = generate_query(pitch_praats)\n",
    "\n",
    "# pitch_JDCs = load_pitch(query_JDC, v = 'JDC')\n",
    "# query_JDCs = generate_query(pitch_JDCs)\n",
    "\n",
    "# print(len(query_labels), len(query_praats), len(query_JDCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-5544fc9ef700>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpitch_JDCs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_pitch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_JDC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'JDC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mquery_JDCs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpitch_JDCs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# print(len(query_labels), len(query_praats), len(query_JDCs))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-42f26e9bfe86>\u001b[0m in \u001b[0;36mgenerate_query\u001b[1;34m(pitchs)\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[0mpitch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpitch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnew_length\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_axis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpitch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mqueries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mqueries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "pitch_JDCs = load_pitch(query_JDC, v = 'JDC')\n",
    "query_JDCs = generate_query(pitch_JDCs)\n",
    "\n",
    "# print(len(query_labels), len(query_praats), len(query_JDCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mulfi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5190,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(pitch_JDCs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(query_labels), len(query_praats), len(query_JDCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.   0. 100. 100. 100.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_eval_arr = np.array([0, 0, 0, 0, 0], dtype='float64')\n",
    "for i in range(len(query_labels)):\n",
    "    eval_arr = melody_eval(query_labels[i], query_praats[i])\n",
    "    avg_eval_arr += eval_arr\n",
    "avg_eval_arr /= len(query_labels)\n",
    "print(avg_eval_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   , 210.965, 210.965, ..., 327.238, 327.238, 327.238])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_labels[0][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.   , 211.877, 210.559, ..., 328.212, 327.836, 327.836])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_praats[0][:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37905e7dff4aaf985345f2c07a6ff2fbd8d44ecc1a00f9be85aabc3321c76ec6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
